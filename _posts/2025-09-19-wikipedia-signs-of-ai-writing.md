---
layout: post
title: Wikipedia's signs of AI writing
subtitle: A helpful guide
cover-img:
thumbnail-img:
share-img: 
tags: Wikipedia, AI
author: Coleton Hast
---

I happened upon this [helpful internal guide on the signs of AI writing](https://en.wikipedia.org/wiki/Wikipedia:Signs_of_AI_writing) for Wikipedia editors and thought I might share it around. 

This guide is meant to "help detect undisclosed AI-generated content on Wikipedia" but is broadly applicable to anyone who is faced with the Sisyphean task of sorting through the walls of AI text we now encounter daily. Rather than take a complete anti-AI position, which would bascially be unenforcable anyway, Wikipedia editors instead identify elements of the style and tone of AI writing and demonstrate how it is both not compatible with Wikipedia's editorial standards, as well as how it can serve as signs of deeper concerns about AI-generated content:

> The patterns here are also only potential signs of a problem, not the problem itself. While many of these issues are immediately obvious and easy to fix—e.g., excessive boldface, poor wordsmithing, broken markup, citation style quirks—they can point to less outwardly visible problems that carry much more serious policy risks. If LLM-generated text is polished enough (initially or subsequently tidied up), those surface defects might not be present, but the deeper problems likely will.

This guide is in addition to [the recent change](https://en.wikipedia.org/wiki/Wikipedia:Speedy_deletion#G15._LLM-generated_pages_without_human_review) which allows for "Speedy Deletion" of LLM-generated articles which clearly lacked human review (as in, they still have header or footer text like "Sure, here is a Wikipedia article on xyz:..."). This also follows [Wikimedia's backtracking](https://arstechnica.com/ai/2025/06/yuck-wikipedia-pauses-ai-summaries-after-editor-revolt/) over the introduction of AI summaries to Wikipedia. Which, ya know, makes sense given that every Wikipedia article _already begins with a human-authored summary_. A key point here is that the Speedy Deletion and Signs of AI writing guide came from the editor community after extensive debate, while AI summaries came top-down from the Wikimedia Foundation.

I found both of these changes, and the processes which led to them, very thoughtful. I think that taking AI-generated content on its merits, as in whether it is good and stylistically appropriate writing, is preferable to a flat-out ban both for the practical reasons of enforcement as well as the way in which it treats AI as a tool rather than some exemplary sci-fi magic box. Like any tool, it is good for some things and bad for others (including, it would seem, generating Wikipedia articles). These changes help eliminate some of the mysticism surrounding AI while also maintaining the integrity of Wikipedia.